# 超越選擇題：校準感知評估揭示大型語言模型在臨床推理中的過度自信 (Beyond Multiple Choice: Calibration-Aware Evaluation Reveals Overconfident Clinical Reasoning in Large Language Models)

> **整合研究文件** — 將 M1（開放式臨床推理）+ M6（校準與選擇性預測）+ M11（多模型交叉監督）整合為統一的論文敘事。
>
> **目標期刊：** Journal of Biomedical Informatics (JBI / IJMI)
>
> **狀態：** 論文已完成，使用真實 API 資料（n=1,273 道 MedQA 題目，GPT-4o，共 3,819 次推論）

---

## 1. 研究問題

### 1.1 MCQ 錯覺（The MCQ Illusion）

醫學 LLM 的評估長期以選擇題（MCQ）基準測試為主——MedQA、USMLE、MMLU-Med。當 GPT-4「通過 USMLE」時，其隱含的主張是它具備臨床推理能力。但 MCQ 格式提供了結構性優勢，使得能力被高估：

- **消去法策略** — 排除明顯錯誤的選項，縮小搜尋空間
- **答案錨定效應** — 正確答案就在選項中，引導模型提取相關知識
- **格式熟悉度** — LLM 在訓練過程中接觸了大量 MCQ 範例

**核心論點：** MCQ 準確率系統性地高估了臨床推理能力。移除選項的鷹架後，會顯現出巨大的 **Option Bias（選項偏差）**——即 MCQ 準確率與開放式臨床正確率之間的落差。這一差距因嚴重的**校準不良（miscalibration）**而加劇：模型即使在準確率下降時仍維持高信心度，製造出危險的能力假象。

### 1.2 為什麼這很重要

- **臨床實務是開放式的** — 醫師不是從 4 個選項中選擇；他們需要從零開始產生鑑別診斷、治療計畫和安全性評估
- **CDSS 部署決策**依賴 MCQ 基準測試——如果這些測試高估了能力，不安全的系統就會被部署
- **警報疲勞（Alert fatigue）** — 過度自信的 AI 產生過多假陽性警報，侵蝕臨床醫師的信任
- **高信心度錯誤**是最危險的——臨床醫師較不可能推翻自信的 AI 建議

### 1.3 研究問題

| # | 問題 | 來源模組 |
|---|------|----------|
| RQ1 | MCQ 格式在多大程度上膨脹了醫學 LLM 的感知準確率？ | M1 |
| RQ2 | 模型信心度校準在 MCQ 與開放式格式之間是否不同？ | M6 |
| RQ3 | 高信心度錯誤的普遍程度如何？其臨床風險為何？ | M6 + M11 |
| RQ4 | 多模型交叉監督能否提高評估可靠性？ | M11 |
| RQ5 | 臨床 AI 評估是否應根據醫學嚴重度對錯誤進行差異化加權？ | M6 (SW-ECE) |

---

## 2. 理論框架

### 2.1 從分散模組到統一評估

本論文整合了 MedEval-X 框架中的三個模組：

```
M1: 開放式推理 ──────── 「它是在推理還是在模式匹配？」
        │
        ├── M6: 校準分析 ──── 「它知不知道自己不知道什麼？」
        │
        └── M11: 交叉監督 ── 「多個模型能否互相抓出錯誤？」
```

**整合邏輯：** M1 建立 MCQ 與開放式格式之間的基線表現差距（即 Option Bias）。M6 分析模型的信心度是否隨準確率下降而調整（校準分析）。M11 提出多模型共識作為大規模偵測過度自信錯誤的實用方案。

### 2.2 三層臨床判斷系統（源自 M1）

標準 MCQ 評估使用二元評分（正確/錯誤）。臨床現實是分級的——一個回答可以「方向正確」但不夠精準。我們引入三層判斷系統：

| 等級 | 標籤 | 定義 | 範例 |
|------|------|------|------|
| **A** | 臨床正確 | 語意上等同於參考答案 | 回答「Inferior STEMI」，參考答案為「ST-elevation MI of inferior wall」 |
| **B** | 部分正確 | 臨床方向正確，但不夠精準 | 回答「Myocardial infarction」，參考答案為「Inferior STEMI」 |
| **C** | 臨床錯誤 | 與參考答案在臨床上截然不同 | 回答「Pulmonary embolism」，參考答案為「Inferior STEMI」 |

這捕捉了二元評分所遺漏的細緻部分正確性——Level B 的回答反映了真正的臨床知識，而非完全失敗。

### 2.3 Safety-Weighted ECE（源自 M6）— 新指標

標準的 Expected Calibration Error (ECE，期望校準誤差) 對所有校準不良一視同仁：解剖學題目上 10% 的過度自信，與藥物劑量題目上 10% 的過度自信受到相同懲罰。在臨床情境中，**並非所有校準不良都同等危險**。

**Safety-Weighted ECE (SW-ECE，安全加權期望校準誤差)** 依臨床領域嚴重程度套用不同權重：

| 醫學領域 | 權重 | 理由 |
|---------|------|------|
| 藥理學（Pharmacology） | 3.0 | 用藥錯誤可能致命 |
| 急診醫學（Emergency Medicine） | 3.0 | 延誤治療可能致命 |
| 兒科（Pediatrics） | 2.5 | 兒童劑量錯誤後果嚴重 |
| 婦產科（OB/GYN） | 2.5 | 孕期用藥安全風險 |
| 內科（Internal Medicine） | 2.0 | 慢性疾病管理影響 |
| 外科（Surgery） | 2.0 | 手術決策後果 |
| 病理學（Pathology） | 1.5 | 診斷判讀影響 |
| 精神科（Psychiatry） | 1.5 | 治療計畫影響 |
| 基礎科學（Basic Sciences） | 1.0 | 間接臨床影響 |

SW-ECE 使校準評估具有臨床意義——一個在藥理學領域校準不良的模型，比在基礎科學領域校準不良的模型更加危險。

---

## 3. 方法學

### 3.1 資料集

**MedQA (USMLE) 完整測試集：** 1,273 道題目，涵蓋多個醫學學科。

主題分佈：「step1」（基礎科學、解剖學、生物化學、藥理學）和「step2&3」（臨床醫學、外科、兒科、精神科、婦產科）。

> **已知限制：** MedQA 的主題分類較粗——僅有「step1」和「step2&3」的標籤。更細緻的子領域分析需使用 MedMCQA（21 個科目標籤），列為未來工作。

### 3.2 實驗設計

每道題以**兩種格式**搭配**語言化信心度（verbalized confidence）**進行評估：

| 格式 | 輸入 | 輸出 | 目的 |
|------|------|------|------|
| **MCQ** | 題目 + 4 個選項 (A/B/C/D) | 所選選項 + 信心度 (0-100%) | 標準基準測試基線 |
| **Open-Ended（開放式）** | 僅題幹（移除選項） | 自由文字回答 + 信心度 (0-100%) | 臨床推理能力評估 |

**模型：** GPT-4o（temperature = 0，確定性輸出）

**評估流程：**
1. MCQ 評估：1,273 次 API 呼叫 → 二元正確/錯誤
2. 開放式評估：1,273 次 API 呼叫 → 自由文字回答
3. 臨床判斷：1,273 次 API 呼叫 → GPT-4o 將每個開放式回答分類為 Level A/B/C
4. **總計：3,819 次模型推論**

### 3.3 Option Bias 指標（源自 M1）

| 指標 | 公式 | 解讀 |
|------|------|------|
| **Option Bias** | Acc_MCQ − Acc_OE(Level A) | MCQ 與開放式格式之間的原始準確率差距 |
| **Adjusted Option Bias** | Acc_MCQ − (Level A + 0.5 × Level B) | 對 Level B 回答給予部分學分 |
| **Relative Option Bias** | (Acc_MCQ − Acc_OE) / Acc_MCQ × 100% | MCQ 準確率中可歸因於格式的百分比 |

### 3.4 校準指標（源自 M6）

| 指標 | 測量內容 |
|------|----------|
| **ECE** | Expected Calibration Error（期望校準誤差）— 10 個區間中信心度與準確率之間的平均差距 |
| **SW-ECE** | Safety-Weighted ECE（安全加權 ECE）— 依臨床領域嚴重程度加權的 ECE |
| **Brier Score** | 準確率與校準的聯合指標（越低越好） |
| **Confidence-Accuracy Gap** | 平均信心度 − 平均準確率（正值 = 過度自信） |
| **Coverage@95%** | 在維持 95% 準確率的前提下，可回答的題目比例（選擇性預測） |

### 3.5 過度自信錯誤分析

**定義：** 模型在不正確的 MCQ 答案上表達 >80% 信心度的案例。

這些是臨床上最危險的情況——高信心度會抑制臨床醫師的推翻行為。我們分析：
- 盛行率（佔所有題目的比例是多少？）
- 集中度（錯誤中有多少比例是高信心度的？）
- 領域分佈（哪些醫學領域有最多過度自信的錯誤？）

---

## 4. 結果

### 4.1 Option Bias 分析（核心發現）

| 指標 | 數值 |
|------|------|
| MCQ 準確率 | **87.8%** (1,119/1,273) |
| 開放式 Level A（精確正確） | **56.2%** (715/1,273) |
| 開放式 Level B（部分正確） | **24.6%** (313/1,273) |
| 開放式 Level C（錯誤） | **19.2%** (245/1,273) |
| **Option Bias** | **31.7 個百分點** |
| Adjusted Option Bias | 19.4 pp |
| Relative Option Bias | **36.0%** |

**解讀：** GPT-4o 的 MCQ 準確率中超過三分之一（36%）可歸因於 MCQ 格式本身，而非真正的臨床推理能力。當移除選項鷹架後，準確率從 87.8% 驟降至 56.2%。

**24.6% 的 Level B（部分正確）** 比率很重要——它意味著大約 25% 的時間裡，模型展現了相關的臨床知識，但缺乏正確臨床行為所需的精確度。這在二元 MCQ 評分中完全無法被捕捉。

### 4.2 校準分析（校準悖論）

| 指標 | MCQ | Open-Ended | 變化 |
|------|-----|------------|------|
| ECE | **0.029** | **0.364** | 惡化 12.6 倍 |
| SW-ECE | 0.029 | 0.364 | 惡化 12.6 倍 |
| Brier Score | 0.103 | 0.372 | 惡化 3.6 倍 |
| 平均信心度 | **90.7%** | **92.5%** | +1.8 pp (↑) |
| 平均準確率 | 87.8% | 56.2% | −31.6 pp (↓) |
| Confidence-Accuracy Gap | **2.9%** | **36.3%** | 惡化 12.5 倍 |

**校準悖論（The Calibration Paradox）：** 模型信心度在轉換到開放式格式時實際上*略微上升*（90.7% → 92.5%），儘管準確率下降了 31.7 個百分點。模型未能認知到它已經失去了 MCQ 的鷹架——它在準確率大幅下降的情境中仍維持同樣的高信心度。

- **MCQ 格式：** 校準良好（ECE = 0.029），信心度與準確率密切追蹤
- **開放式格式：** 嚴重校準不良（ECE = 0.364），信心度與準確率差距達 36.3%

### 4.3 過度自信的錯誤案例

| 指標 | 數值 |
|------|------|
| 過度自信且錯誤的總數（>80% 信心度，MCQ 答錯） | **147 / 1,273 = 11.5%** |
| 佔所有 MCQ 錯誤的比例 | **147 / 155 = 94.8%** |

**關鍵發現：** 幾乎所有 MCQ 錯誤（94.8%）都發生在高信心度的情況下。模型在答錯時幾乎從不表達低信心度——它不是「答對且自信」就是「答錯且自信」。這意味著信心度無法作為可靠的安全過濾器。

### 4.4 信心度分佈

- **MCQ 正確答案：** 信心度緊密分佈在 90-95% 區間
- **MCQ 錯誤答案：** 信心度同樣很高（94.8% 的錯誤信心度 >80%）
- **開放式正確：** 高信心度（約 90-95%）
- **開放式錯誤：** 高信心度（約 85-95%，與正確答案重疊）

在開放式格式中，正確與錯誤答案的信心度分佈**幾乎重疊**，使得基於信心度的分流機制失效。

---

## 5. 討論

### 5.1 MCQ 錯覺：對臨床 AI 評估的意涵

「GPT-4 通過 USMLE」這類頭條是基於 MCQ 評估。我們的 Option Bias 為 31.7%，顯示此類說法大約高估了三分之一的臨床推理能力。這對政策有直接影響：

- **監管框架**（FDA SaMD、EU AI Act）若依賴基準測試準確率，可能核准表現被誇大的系統
- **醫院採購決策**若基於 MCQ 基準測試，可能高估已部署系統的實際能力
- **公眾信任**可能被誤導，如果評估方法不具臨床代表性

### 5.2 校準悖論：為什麼信心度作為安全信號會失敗

「模型會知道自己不知道什麼」這個預期，是許多 CDSS 部署架構的基礎——將低信心度案例轉交人工審查，自動通過高信心度案例。我們的研究發現這個假設失敗了：

- 在 MCQ 格式中，校準表現優秀（ECE = 0.029）——在 MCQ 框架內驗證了這個假設
- 在開放式格式中，校準崩潰（ECE = 0.364）——在臨床情境中否定了基於信心度的分流
- **格式遷移失敗**意味著在 MCQ 基準測試上驗證的校準，無法預測臨床部署中的校準表現

### 5.3 過度自信與病人安全

147 個過度自信且錯誤的案例（11.5%）代表最危險的失敗模式：

- **警報疲勞放大效應：** 如果每個高信心度的 AI 建議都被視為可靠，其中 11.5% 將是錯誤的
- **推翻抗拒：** 臨床醫師較不可能推翻自信的 AI，即使他們自己的判斷不同
- **錯誤集中：** 94.8% 的錯誤是高信心度的——模型幾乎從不提供「我不確定」的信號來觸發人工審查

### 5.4 Safety-Weighted ECE：並非所有校準不良都同等重要

標準 ECE 將生物化學題目上 10% 的過度自信等同於兒科藥物劑量題目上 10% 的過度自信。在臨床部署中：
- 藥理學校準不良 → 潛在用藥錯誤 → 病人傷害
- 基礎科學校準不良 → 概念性誤解 → 無直接病人影響

SW-ECE 透過依領域嚴重程度加權校準不良來解決此問題。雖然在本資料集中 MCQ 的 SW-ECE 和 ECE 恰好相同（0.029），但在評估具有不同風險特徵的臨床領域時，此指標變得至關重要。

### 5.5 三層臨床 AI 篩選框架

我們提議醫療 AI 系統在部署前應經過三層評估：

| 層級 | 評估內容 | 揭示什麼 |
|------|----------|----------|
| **第一層：能力（Competence）** | MCQ + 開放式準確率、Option Bias | 真正的推理能力 vs 格式依賴 |
| **第二層：自我認知（Self-Awareness）** | ECE、SW-ECE、Coverage@95% | 模型是否知道自己不知道什麼 |
| **第三層：穩健性（Robustness）** | 多模型交叉監督、集成一致性 | 錯誤是否能被互補模型捕捉 |

第三層利用 M11 的多模型共識：當多樣化的模型達成共識時，信心是有根據的；當它們不一致時，案例會被標記進行人工審查。與四家雲端服務商（OpenAI、Anthropic、Google、DeepSeek）的初步先導測試表明，雖然模型在明確案例上（例如 ACE inhibitor 在懷孕期間的禁忌）達成共識，但在細緻的治療選擇上產生分歧——驗證了集成不一致性作為實用不確定性信號的可行性。

### 5.6 限制

1. **單一模型** — 僅評估 GPT-4o；研究發現可能無法推廣到所有模型
2. **自動化判斷** — GPT-4o 作為臨床判斷者，可能引入系統性偏差
3. **單一資料集** — 僅使用 MedQA；MedMCQA（21 個科目）和 MMLU-Med 規劃於未來進行
4. **粗糙主題分類** — 僅有「step1」/「step2&3」；尚無法進行更細緻的子領域分析
5. **簡化語意匹配** — 未使用 SNOMED CT 本體論進行 Level A/B/C 分類
6. **無多模型校準比較** — 僅分析 GPT-4o 的校準；跨模型校準比較列為未來計畫

---

## 6. 結論

我們證明了基於 MCQ 的評估使醫學 LLM 的準確率膨脹了 31.7 個百分點（相對 36%），產生了危險的 **MCQ 錯覺**。更糟糕的是，當準確率下降時模型信心度並未降低——校準悖論意味著基於信心度的安全機制在開放式臨床情境中失效。由於 94.8% 的錯誤發生在高信心度下，模型基本上不提供任何自我修正信號。

我們引入 Safety-Weighted ECE 使校準評估具有臨床意義，並提出三層篩選框架（能力 + 自我認知 + 穩健性）作為臨床 AI 部署的最低標準。這些發現挑戰了「基準測試表現等同於臨床安全」的假設，並主張開放式、校準感知的評估應成為監管要求。

---

## 7. 模組整合地圖

### 各模組的貢獻

| 模組 | 在論文中的角色 | 使用的章節 |
|------|---------------|-----------|
| **M1**（開放式推理） | **核心方法學** — MCQ vs 開放式比較、三層判斷、Option Bias 指標 | 方法 §3.1-3.3、結果 §4.1、討論 §5.1 |
| **M6**（校準分析） | **校準分析** — ECE、SW-ECE、Brier Score、過度自信錯誤分析 | 方法 §3.4-3.5、結果 §4.2-4.4、討論 §5.2-5.4 |
| **M11**（多模型交叉監督） | **解決方案框架** — 多模型集成作為不確定性信號、三層篩選；已與 4 家雲端服務商進行初步先導測試 | 討論 §5.5 |

### 相較於個別模組的變更

| 原始模組範圍 | 論文範圍 | 原因 |
|-------------|---------|------|
| M1：6,256 道 MCQ → 跨 3 個資料集的開放式評估、SNOMED CT 匹配 | 僅 1,273 道 MedQA、GPT-4o 判斷 | 重深度（完整資料集、真實 API）而非廣度 |
| M6：4 種信心度方法（語言化、自我一致性、集成、logit） | 僅語言化信心度 | 自我一致性（10 倍成本）和 logit 基（僅限本地模型）延至多模型論文 |
| M11：3 種共識策略、500 道題、失敗模式分析 | 討論中的概念框架 | 完整 M11 實驗規劃為擴展研究；此處提供理論解決方案 |

### 與其他論文的關聯

| 論文 | 共通概念 | 關係 |
|------|---------|------|
| **paper_safety**（M4+M5+M8+M3） | 過度自信概念、校準 | Safety 論文將校準洞見專門應用於藥物安全性 |
| **paper_aesop**（M9+M7+M2） | 去偏差、結構化提示 | Aesop 論文測試結構化提示是否能修正此處發現的過度自信 |

---

## 8. 實驗基礎設施

### 8.1 程式碼

| 檔案 | 用途 |
|------|------|
| `run_experiment.py` | MCQ vs OE 實驗流程，含語言化信心度與校準指標 |

### 8.2 結果

| 檔案 | 內容 |
|------|------|
| `results_foundation_full.json` | GPT-4o 完整資料集（n=1,273）原始 API 結果 |

### 8.3 圖表

| 圖表 | 檔案 | 內容 |
|------|------|------|
| 圖 1 | `figures/option_bias_bar_chart.png` | MCQ vs OE 表現比較 |
| 圖 2 | `figures/reliability_diagram_mcq.png` | 可靠性圖 — MCQ (ECE=0.029) |
| 圖 3 | `figures/reliability_diagram_oe.png` | 可靠性圖 — OE (ECE=0.364) |
| 圖 4 | `figures/confidence_distribution.png` | 信心度分佈：正確 vs 錯誤 |

---

## 9. 關鍵術語

| 術語 | 定義 |
|------|------|
| **Option Bias（選項偏差）** | MCQ 與開放式格式之間的準確率差距（衡量格式依賴程度） |
| **Adjusted Option Bias（調整後選項偏差）** | 對 Level B 回答給予部分學分後的 Option Bias |
| **ECE（期望校準誤差）** | Expected Calibration Error — 信心度與準確率之間的平均差距 |
| **SW-ECE（安全加權期望校準誤差）** | Safety-Weighted ECE — 依臨床領域嚴重程度加權的 ECE |
| **Level A/B/C（三層臨床判斷）** | 正確 / 部分正確 / 錯誤 |
| **Calibration Paradox（校準悖論）** | 信心度在跨格式準確率下降時仍維持高水準 |
| **Coverage@95%（95% 準確率覆蓋率）** | 在維持 95% 準確率的前提下可回答的題目比例 |
| **Overconfident-Wrong（過度自信且錯誤）** | 在不正確答案上信心度 >80% |
| **MCQ Illusion（MCQ 錯覺）** | 因 MCQ 分數膨脹而產生的臨床能力假象 |
| **Selective Prediction（選擇性預測）** | 基於信心度閾值將不確定案例轉交人工審查 |
