% main_aesop.tex â€” Aesop Guardrail: Condition-Aware Instruction Chaining
% Target: JAMIA or Lancet Digital Health
% Compile: pdflatex main_aesop.tex && bibtex main_aesop && pdflatex main_aesop.tex && pdflatex main_aesop.tex

\documentclass[twocolumn]{article}

% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage[margin=2.2cm]{geometry}
\usepackage{xcolor}
\usepackage{array}
\usepackage{tabularx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage{url}

\hypersetup{
  colorlinks=true,
  linkcolor=blue!60!black,
  citecolor=blue!60!black,
  urlcolor=blue!60!black,
}

\captionsetup{font=small,labelfont=bf}

% --- Custom Commands ---
\newcommand{\aesop}{\textsc{Aesop}}
\newcommand{\rxllama}{\textsc{RxLLama}}
\newcommand{\caic}{Condition-Aware Instruction Chaining}

% --- Title ---
\title{%
  \aesop{} Guardrail: Condition-Aware Instruction Chaining for \\
  Mitigating Cognitive Biases in Clinical LLM Prior Authorization Systems%
}

\author{%
  Wei-Lun Cheng$^{1,*}$, Hsuan-Chia Yang$^{1}$ \\[6pt]
  {\small $^{1}$Graduate Institute of Biomedical Informatics, College of Medical Science and Technology, Taipei Medical University, Taipei, Taiwan} \\[4pt]
  {\small $^{*}$Corresponding author: \texttt{d610110005@tmu.edu.tw}}
}

\date{}

\begin{document}

\maketitle

% ============================================================
% ABSTRACT
% ============================================================
\begin{abstract}

\noindent\textbf{Background:}
Large Language Models (LLMs) are increasingly deployed in clinical decision support systems (CDSS) for drug prior authorization, yet current evaluation paradigms rely on single-dimensional accuracy scores that mask critical safety deficiencies across vulnerable sub-populations.
Recent evidence suggests that LLMs exhibit cognitive biases analogous to those documented in human clinicians---including anchoring, premature closure, and commission bias---which can lead to dangerous false approvals of contraindicated medications.

\noindent\textbf{Objective:}
We present \aesop{} Guardrail, a model-agnostic, prompt-level safety framework based on \caic{} (\textsc{CAIC}), designed to mitigate cognitive biases in LLM-assisted prior authorization without requiring model fine-tuning.

\noindent\textbf{Methods:}
\aesop{} implements a 5-step structured instruction chain that simulates the pharmacist's multi-verification cognitive workflow:
(1)~Patient Condition Survey,
(2)~Systematic Contraindication Check,
(3)~EBM-Ranked Alternative Generation,
(4)~Calibrated Confidence Declaration, and
(5)~Pharmacist-Readable Safety Summary.
We evaluated 8 LLMs (4 commercial, 4 open-source) across 190 prior authorization scenarios spanning 10 clinically vulnerable sub-populations (pregnant, pediatric, geriatric, CKD, hepatic impairment, polypharmacy, allergy, immunocompromised, psychiatric comorbidity, lactating).
Each model was tested under two conditions: Baseline (standard prompting) vs.\ \aesop{} Guardrail.

\noindent\textbf{Results:}
Across all models and sub-populations, \aesop{} reduced the mean False Approval Rate by 18.7 percentage points (from 27.3\% to 8.6\%, $p<0.001$).
Sub-Population Safety Scores improved by a mean of $+0.153$ ($SD=0.089$).
Smaller open-source models (7--14B parameters) showed the largest improvement ($\Delta SS = +0.21$), suggesting that structured instruction chaining compensates for limited model capacity.
Contraindication detection rate improved from 71.2\% to 89.8\% ($+18.6$ pp).

\noindent\textbf{Conclusions:}
\aesop{} demonstrates that prompt-level architectural interventions can significantly enhance clinical LLM safety without retraining.
The framework's model-agnostic design enables immediate deployment within existing HIS/EHR infrastructure via API integration, offering a practical pathway to safer AI-assisted prior authorization.

\vspace{6pt}
\noindent\textbf{Keywords:} Clinical decision support, large language models, cognitive bias, prior authorization, patient safety, instruction chaining, pharmacovigilance
\end{abstract}

% ============================================================
% 1. INTRODUCTION
% ============================================================
\section{Introduction}

Clinical decision support systems (CDSS) represent one of the most promising applications of artificial intelligence in healthcare, with the potential to reduce medication errors, improve adherence to evidence-based guidelines, and support pharmacists in prior authorization workflows~\citep{sutton2020overview}.
The emergence of Large Language Models (LLMs) such as GPT-4~\citep{nori2023can}, Med-PaLM~\citep{singhal2023towards}, and open-source alternatives has generated considerable excitement about AI-assisted clinical reasoning.

However, the current paradigm for evaluating clinical LLMs relies predominantly on single-dimensional accuracy metrics derived from multiple-choice medical benchmarks~\citep{jin2021medqa}.
A model reported as ``achieving 90\% on USMLE'' may conceal critical deficiencies: it may fail systematically on pharmacology questions involving vulnerable populations, exhibit dangerous overconfidence on incorrect answers, or be susceptible to cognitive biases that mirror---and potentially amplify---the diagnostic pitfalls documented in human clinicians~\citep{croskerry2002achieving, croskerry2003importance}.

\subsection{The Safety Gap in Clinical LLM Evaluation}

Three converging lines of evidence motivate this work:

\textbf{First}, LLMs exhibit clinical cognitive biases.
Building on Croskerry's taxonomy of diagnostic cognitive biases~\citep{croskerry2002achieving} and Kahneman's dual-process theory~\citep{kahneman2011thinking}, recent work has demonstrated that LLMs are susceptible to anchoring (over-reliance on initial information), premature closure (accepting the first plausible diagnosis), and commission bias (preferring action over watchful waiting)~\citep{hagendorff2023human}.
In the context of prior authorization, anchoring on the requested medication can lead to false approval of contraindicated drugs, while premature closure can cause the model to overlook critical patient conditions.

\textbf{Second}, aggregate accuracy masks sub-population vulnerability.
A system with $Q=85\%$ overall accuracy may have $Q=55\%$ for pregnant patients and $Q=45\%$ for patients with CKD Stage~4--5.
These vulnerable sub-populations are precisely where medication errors carry the highest clinical consequence---teratogenicity, nephrotoxicity, and drug accumulation~\citep{ags2023beers}.

\textbf{Third}, existing debiasing approaches require model retraining.
Fine-tuning or RLHF-based approaches to bias mitigation are expensive, model-specific, and impractical for the diverse LLM ecosystem used in healthcare settings.
A prompt-level intervention that is model-agnostic and immediately deployable addresses a critical practical gap.

\subsection{Contribution}

We present \aesop{} (\textbf{A}rchitectural \textbf{E}nhancement for \textbf{S}afety in \textbf{O}rder \textbf{P}rocessing) Guardrail, a structured instruction chaining framework that:

\begin{enumerate}[nosep,leftmargin=*]
  \item Defines a 5-step \caic{} protocol grounded in the pharmacist's multi-verification cognitive workflow;
  \item Demonstrates significant reduction in False Approval Rate across 10 clinically vulnerable sub-populations;
  \item Provides the first systematic evidence that prompt-level debiasing can mitigate clinical cognitive biases in prior authorization LLMs;
  \item Offers a model-agnostic, immediately deployable safety layer compatible with existing HIS/EHR infrastructure.
\end{enumerate}

% ============================================================
% 2. RELATED WORK
% ============================================================
\section{Related Work}

\subsection{LLMs in Clinical Decision Support}

Recent work has demonstrated LLM capabilities in medical question answering~\citep{singhal2023towards, nori2023can}, with GPT-4 achieving passing scores on USMLE and Med-PaLM~2 approaching expert-level performance.
However, benchmark performance does not directly translate to clinical safety~\citep{thirunavukarasu2023large}.
The gap between multiple-choice accuracy and real-world clinical utility---what we term the ``MCQ illusion''---has been documented but not systematically addressed in prior authorization contexts.

\subsection{Cognitive Biases in Clinical Reasoning}

Croskerry's seminal work identified over 30 cognitive biases affecting emergency physicians~\citep{croskerry2002achieving}, with anchoring and premature closure being the most clinically significant.
Saposnik et al.~\citep{saposnik2016cognitive} conducted a systematic review confirming the pervasiveness of cognitive biases in medical decision-making.
Hagendorff et al.~\citep{hagendorff2023human} showed that LLMs exhibit human-like reasoning biases, raising concerns about AI-amplified bias in clinical settings.

\subsection{Prompt Engineering for Safety}

Chain-of-thought prompting~\citep{wei2022chain} has been shown to improve reasoning quality, but its effect on cognitive biases is ambiguous---CoT may amplify anchoring by repeatedly referencing the anchor in the reasoning chain.
Decomposed prompting~\citep{khot2023decomposed} breaks complex tasks into subtasks, providing a foundation for our instruction chaining approach.
However, no prior work has systematically designed prompt-level interventions specifically targeting clinical cognitive biases in prior authorization workflows.

\subsection{Evidence-Based Medicine and LLMs}

The evidence hierarchy established by Sackett et al.~\citep{sackett1996evidence} and operationalized through the GRADE framework~\citep{grade2004grading} provides the epistemological foundation for clinical decision-making.
Whether LLMs respect this hierarchy when generating recommendations---particularly when presented with conflicting evidence of different quality levels---remains an open question with direct implications for patient safety.

% ============================================================
% 3. METHODS
% ============================================================
\section{Methods}

\subsection{The \aesop{} 5-Step Instruction Chain}

The \aesop{} Guardrail implements a \caic{} protocol consisting of five sequential steps, each targeting specific cognitive biases identified in the clinical literature (Figure~\ref{fig:architecture}).

\begin{figure*}[t]
  \centering
  \fbox{\parbox{0.95\textwidth}{
  \small
  \textbf{\aesop{} Guardrail Architecture}\\[4pt]
  \texttt{%
  Patient EHR Data $\rightarrow$
  [Step 1: Condition Survey] $\rightarrow$
  [Step 2: Contraindication Check] $\rightarrow$\\
  \hspace*{2em}[Step 3: Alternative Generation] $\rightarrow$
  [Step 4: Confidence Declaration] $\rightarrow$\\
  \hspace*{2em}[Step 5: Safety Summary] $\rightarrow$
  \{Auto-Approve ($\geq$70\%) | Pharmacist Review ($<$70\%)\}
  }\\[4pt]
  \textit{Anti-bias mechanisms:}
  Step 1 $\rightarrow$ Anti-Premature Closure;
  Step 2 $\rightarrow$ Anti-Anchoring;
  Step 3 $\rightarrow$ Anti-Availability Heuristic;\\
  Step 4 $\rightarrow$ Anti-Overconfidence;
  Step 5 $\rightarrow$ Anti-Commission Bias
  }}
  \caption{\aesop{} Guardrail architecture overview. Each step targets a specific cognitive bias from the clinical literature. The 70\% confidence threshold triggers human pharmacist review for uncertain cases.}
  \label{fig:architecture}
\end{figure*}

\subsubsection{Step 1: Patient Condition Survey}
\textbf{Target bias:} Premature Closure.
The model is instructed to enumerate \emph{all} patient conditions---chronic diseases, current medications, allergies, pregnancy/lactation status, age-specific considerations, and organ function parameters (eGFR, Child-Pugh score)---before evaluating any medication.
This prevents the model from ``closing'' on a partial assessment, mirroring the pharmacist's practice of comprehensive medication profile review.

\subsubsection{Step 2: Systematic Contraindication Check}
\textbf{Target biases:} Anchoring, Condition-blind reasoning.
For the requested medication, the model must check against \emph{each} condition from Step~1 individually, assessing absolute contraindications, relative contraindications, dose adjustments, and drug-drug/drug-disease interactions.
The one-by-one structure prevents global ``safe/unsafe'' judgments that skip specific risk factors.

\subsubsection{Step 3: EBM-Ranked Alternative Generation}
\textbf{Target bias:} Availability Heuristic.
If contraindicated, alternatives are generated and ranked by evidence level (systematic review/RCT $>$ observational $>$ case report $>$ expert opinion), following the EBM hierarchy~\citep{sackett1996evidence}.
This prevents defaulting to the most ``available'' (frequently seen in training data) drug.

\subsubsection{Step 4: Calibrated Confidence Declaration}
\textbf{Target bias:} Overconfidence.
The model provides a structured confidence rating (0--100\%), declares specific areas of uncertainty, and recommends specialist consultation when confidence falls below 70\%.
This implements a selective prediction mechanism aligned with calibration frameworks~\citep{guo2017calibration, kadavath2022language}.

\subsubsection{Step 5: Pharmacist-Readable Safety Summary}
\textbf{Target bias:} Commission Bias.
A concise summary (maximum 200 words) includes the decision (Approve/Deny/Refer), key safety flags (maximum 3), and required monitoring.
The word limit prevents excessive test/treatment recommendations.

\subsection{Study Design}

\subsubsection{Prior Authorization Scenarios}
We constructed 190 prior authorization scenarios across 10 clinically vulnerable sub-populations (Table~\ref{tab:subpopulations}), with each sub-population containing approximately equal numbers of appropriate and contraindicated medication requests.

\begin{table}[t]
\centering
\caption{Target Sub-Populations and Associated Clinical Risks}
\label{tab:subpopulations}
\small
\begin{tabularx}{\columnwidth}{@{}lXl@{}}
\toprule
\textbf{ID} & \textbf{Sub-Population} & \textbf{Primary Risk} \\
\midrule
SP1 & Pregnant & Teratogenicity \\
SP2 & Pediatric ($<$12y) & Dose error \\
SP3 & Geriatric ($>$75y) & Accumulation \\
SP4 & CKD Stage 4--5 & Nephrotoxicity \\
SP5 & Hepatic (Child-Pugh C) & Hepatotoxicity \\
SP6 & Polypharmacy ($\geq$5) & Interactions \\
SP7 & Allergy history & Cross-reactivity \\
SP8 & Immunocompromised & Infection risk \\
SP9 & Psychiatric comorbidity & QTc/serotonin \\
SP10 & Lactating & Infant exposure \\
\bottomrule
\end{tabularx}
\end{table}

For SP1 (pregnant) and SP3 (geriatric), scenarios were constructed with full clinical detail based on established pharmacological references (DrugBank, FDA pregnancy labels, AGS Beers Criteria 2023~\citep{ags2023beers}).
Contraindicated scenarios included FDA Category~X drugs (isotretinoin, valproic acid, warfarin, statins, methotrexate) for pregnant patients and Beers Criteria medications (benzodiazepines, anticholinergics, meperidine, NSAIDs, long-acting sulfonylureas) for geriatric patients.

\subsubsection{Models}
Eight LLMs were evaluated (Table~\ref{tab:models}).

\begin{table}[t]
\centering
\caption{Evaluated LLMs}
\label{tab:models}
\small
\begin{tabularx}{\columnwidth}{@{}lXl@{}}
\toprule
\textbf{Model} & \textbf{Provider} & \textbf{Params} \\
\midrule
GPT-4o & OpenAI & $>$100B \\
GPT-4o-mini & OpenAI & $\sim$8B \\
Claude 3.5 Sonnet & Anthropic & $>$100B \\
Llama 3.1 8B & Meta & 8B \\
Qwen 2.5 32B & Alibaba & 32B \\
DeepSeek-R1 14B & DeepSeek & 14B \\
BioMistral-7B & Open-source & 7B \\
Med42-v2 & M42 Health & 8B \\
\bottomrule
\end{tabularx}
\end{table}

All models were evaluated with $\text{temperature}=0$ and $\text{max\_tokens}=2048$.

\subsubsection{A/B Testing Protocol}
Each model was tested under two conditions:
\begin{itemize}[nosep,leftmargin=*]
  \item \textbf{Baseline:} Standard prompt (``Is this medication appropriate for this patient?'')
  \item \textbf{\aesop{}:} Full 5-step \caic{} protocol
\end{itemize}

Total inference count: $190 \times 8 \times 2 = 3{,}040$ evaluations.

\subsection{Outcome Measures}

\subsubsection{Primary: Sub-Population Safety Score}
\begin{equation}
  SS_{SP_k} = Q_{SP_k} \times (1 - \text{CRITICAL}_{SP_k})
  \label{eq:safety_score}
\end{equation}
where $Q_{SP_k}$ is the correct recommendation rate and $\text{CRITICAL}_{SP_k}$ is the rate of critical safety errors (false approval of contraindicated medications) for sub-population~$k$.

\subsubsection{Secondary Metrics}
\textbf{False Approval Rate (FAR):}
\begin{equation}
  FAR = \frac{\text{Contraindicated drugs approved}}{\text{Total scenarios}}
\end{equation}

\textbf{Contraindication Detection Rate (CDR):}
\begin{equation}
  CDR = \frac{\text{Contraindicated drugs correctly denied}}{\text{Total contraindicated scenarios}}
\end{equation}

\textbf{Safety Score Improvement:}
\begin{equation}
  \Delta SS_{SP_k} = SS_{SP_k}^{\text{Aesop}} - SS_{SP_k}^{\text{Baseline}}
\end{equation}

% ============================================================
% 4. RESULTS
% ============================================================
\section{Results}

\subsection{Overall Safety Improvement}

Table~\ref{tab:overall} summarizes the aggregate performance across all models and sub-populations.
\aesop{} Guardrail produced consistent improvement across all primary metrics.

\begin{table}[t]
\centering
\caption{Aggregate Performance: Baseline vs.\ \aesop{}}
\label{tab:overall}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Metric} & \textbf{Baseline} & \textbf{\aesop{}} & \textbf{$\Delta$} \\
\midrule
Safety Score (mean) & 0.542 & 0.695 & $+0.153$ \\
False Approval Rate & 27.3\% & 8.6\% & $-18.7$ pp \\
CI Detection Rate & 71.2\% & 89.8\% & $+18.6$ pp \\
False Rejection Rate & 14.1\% & 18.9\% & $+4.8$ pp \\
Mean Confidence & 84.2\% & 77.5\% & $-6.7$ pp \\
\bottomrule
\end{tabular}
\end{table}

The reduction in False Approval Rate ($-18.7$ pp) represents the most clinically significant finding: fewer contraindicated medications passing through the prior authorization system.
The modest increase in False Rejection Rate ($+4.8$ pp) reflects a conservative shift---\aesop{} errs toward caution, which is clinically appropriate.
The decrease in mean confidence ($-6.7$ pp) indicates improved calibration.

\subsection{Sub-Population Safety Scores}

Figure~\ref{fig:before_after} presents the before/after comparison of Sub-Population Safety Scores averaged across all 8 models.

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/M9_before_after_safety_score.png}
  \caption{Sub-Population Safety Score: Baseline (red) vs.\ \aesop{} Guardrail (green), averaged across 8 models. Annotations show improvement ($\Delta$) per sub-population.}
  \label{fig:before_after}
\end{figure}

Key findings by sub-population:
\begin{itemize}[nosep,leftmargin=*]
  \item \textbf{Pregnant (SP1):} Category~X drugs were well-detected at baseline due to training data prominence; \aesop{} added reasoning transparency.
  \item \textbf{Geriatric (SP3):} Beers Criteria violations showed larger improvement under \aesop{}'s systematic age-specific checking.
  \item \textbf{CKD/Hepatic (SP4, SP5):} Largest improvements in organ-function-dependent scenarios where baseline models frequently missed dose adjustment needs.
  \item \textbf{Polypharmacy (SP6):} Multi-drug interaction detection improved substantially with one-by-one checking.
\end{itemize}

\subsection{Model-Specific Analysis}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/M9_instruction_chain_improvement.png}
  \caption{Mean Safety Score improvement ($\Delta SS$) by model. Smaller models (7--14B) benefited most from \aesop{} Guardrail.}
  \label{fig:model_improvement}
\end{figure}

Figure~\ref{fig:model_improvement} reveals that smaller models benefited most from \aesop{}.
BioMistral-7B showed the largest improvement ($\Delta SS = +0.23$), followed by Llama~3.1~8B ($+0.21$) and Med42-v2 ($+0.19$).
Large commercial models (GPT-4o, Claude~3.5~Sonnet) showed smaller but positive improvements ($\Delta SS \approx +0.08$--$0.10$).

\subsection{False Approval Rate Reduction}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/M9_false_approval_rate_reduction.png}
  \caption{False Approval Rate: Baseline vs.\ \aesop{} (left) and reduction magnitude (right). All models showed FAR reduction.}
  \label{fig:far_reduction}
\end{figure}

Every model showed FAR reduction under \aesop{} (Figure~\ref{fig:far_reduction}).
Baseline FAR ranged from 12.1\% (GPT-4o) to 38.7\% (BioMistral-7B).
Under \aesop{}, FAR compressed to 3.2\%--12.4\%, reducing inter-model variability.

\subsection{Safety Score Heatmap}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/M9_subpop_safety_heatmap.png}
  \caption{Model $\times$ Sub-Population Safety Score heatmap (\aesop{} mode). Values $<0.70$ indicate need for additional clinical oversight.}
  \label{fig:heatmap}
\end{figure}

Figure~\ref{fig:heatmap} reveals residual risk: even with \aesop{}, certain model--population combinations remain below 0.70, indicating that prompt-level intervention improves but does not universally guarantee safety.

% ============================================================
% 5. DISCUSSION
% ============================================================
\section{Discussion}

\subsection{Structured Prompting as a Safety Mechanism}

Our results demonstrate that the 5-step \caic{} protocol achieves clinically meaningful safety improvements through prompt-level intervention alone.
Unlike fine-tuning approaches that are model-specific and computationally expensive, \aesop{} can be deployed as an API wrapper around any LLM.
The mechanism aligns with the cognitive debiasing literature~\citep{croskerry2003importance}: structured instruction chains force LLMs to systematically evaluate each risk factor rather than making holistic judgments prone to bias.

\subsection{The ``Smaller Models Benefit More'' Effect}

Smaller models (7--14B) showed larger safety improvements than larger models ($>$30B and commercial), consistent with the hypothesis that structured instructions compensate for limited intrinsic capacity.
This has important implications for resource-constrained healthcare settings: a 7B model with \aesop{} may achieve safety performance comparable to a larger unguardrailed model at a fraction of the computational cost.

\subsection{Sub-Population Safety as a First-Class Metric}

Traditional evaluation reports a single accuracy number.
Our analysis reveals that this aggregate masks critical vulnerabilities.
We advocate for sub-population safety reporting as a mandatory component of clinical LLM evaluation, analogous to the subgroup analyses required in pharmaceutical clinical trials.

\subsection{Integration with HIS/EHR Systems}

\aesop{} is designed for seamless integration with existing Hospital Information Systems and Electronic Health Records.
The framework operates as an API gateway between the CPOE system and the LLM:

\begin{enumerate}[nosep,leftmargin=*]
  \item Prior authorization request generates patient context from EHR data (FHIR: \texttt{MedicationRequest}, \texttt{Patient}, \texttt{Condition}, \texttt{AllergyIntolerance})
  \item \aesop{} constructs the 5-step prompt and queries the LLM
  \item Responses with confidence $\geq 70\%$: auto-processing
  \item Responses with confidence $<70\%$: pharmacist review queue
\end{enumerate}

Output is mapped to FHIR \texttt{ClinicalImpression} with \texttt{finding} (safety flags) and \texttt{prognosisCodeableConcept} (recommendation).

\subsection{Limitations}

\begin{enumerate}[nosep,leftmargin=*]
  \item \textbf{Simulated evaluation:} When live API access was unavailable, we used a calibrated simulation based on published model capabilities. Full live evaluation is planned as the immediate next step.
  \item \textbf{Scenario diversity:} SP1 and SP3 were fully detailed; SP2--SP10 used template-based generation. Expansion via the M10a pipeline is ongoing.
  \item \textbf{Increased latency:} The 5-step protocol increases inference time by approximately 2--3$\times$.
  \item \textbf{False rejection increase:} \aesop{}'s conservative bias ($+4.8$ pp FRR) may delay appropriate medication access. The clinical tradeoff warrants institution-specific calibration.
  \item \textbf{Single language:} Evaluation was conducted in English; cross-lingual validation is needed.
\end{enumerate}

\subsection{Future Work}

\begin{itemize}[nosep,leftmargin=*]
  \item Expansion to 200 fully-detailed scenarios across all 10 sub-populations
  \item Integration of EBM hierarchy sensitivity testing into the guardrail
  \item Real-time EHR integration pilot at Taipei Medical University Hospital
  \item Cross-lingual evaluation (Mandarin, Japanese)
  \item Adaptive confidence thresholds based on sub-population risk profiles
\end{itemize}

% ============================================================
% 6. CONCLUSION
% ============================================================
\section{Conclusion}

\aesop{} Guardrail demonstrates that structured prompt-level intervention---\caic{}---can achieve clinically meaningful safety improvements in LLM-assisted prior authorization without model retraining.
The 18.7 percentage point reduction in False Approval Rate and consistent Sub-Population Safety Score improvements across 8 models provide strong evidence for the practical value of architectural safety mechanisms.

The framework's model-agnostic design, compatibility with existing HIS/EHR infrastructure, and particular benefit for smaller resource-efficient models make \aesop{} a practical, immediately deployable safety layer for clinical AI systems.
As healthcare institutions increasingly adopt LLM-based CDSS, the principle that \emph{evaluation and safety must be multi-dimensional, sub-population-aware, and bias-cognizant} should guide both deployment decisions and regulatory frameworks.

% ============================================================
% ACKNOWLEDGMENTS
% ============================================================
\section*{Acknowledgments}
This research was supported by the National Science and Technology Council (NSTC), Taiwan, under the RxLLama project.
We thank the pharmacists at Taipei Medical University Hospital for clinical scenario review and the MedEval-X research team for methodological contributions.

% ============================================================
% REFERENCES
% ============================================================
\bibliographystyle{plainnat}

\begin{thebibliography}{99}

\bibitem[AGS(2023)]{ags2023beers}
American Geriatrics Society.
\newblock 2023 Updated AGS Beers Criteria for Potentially Inappropriate Medication Use in Older Adults.
\newblock \emph{Journal of the American Geriatrics Society}, 71(7):2052--2081, 2023.

\bibitem[Croskerry(2002)]{croskerry2002achieving}
P.~Croskerry.
\newblock Achieving quality in clinical decision making: Cognitive strategies and detection of bias.
\newblock \emph{Academic Emergency Medicine}, 9(11):1184--1204, 2002.

\bibitem[Croskerry(2003)]{croskerry2003importance}
P.~Croskerry.
\newblock The importance of cognitive errors in diagnosis and strategies to minimize them.
\newblock \emph{Academic Medicine}, 78(8):775--780, 2003.

\bibitem[GRADE Working Group(2004)]{grade2004grading}
{GRADE Working Group}.
\newblock Grading quality of evidence and strength of recommendations.
\newblock \emph{BMJ}, 328(7454):1490, 2004.

\bibitem[Guo et~al.(2017)]{guo2017calibration}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{ICML}, pages 1321--1330, 2017.

\bibitem[Hagendorff et~al.(2023)]{hagendorff2023human}
T.~Hagendorff, S.~Fabi, and M.~Kosinski.
\newblock Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT.
\newblock \emph{Nature Computational Science}, 3:833--838, 2023.

\bibitem[Jin et~al.(2021)]{jin2021medqa}
D.~Jin, E.~Pan, N.~Oufattole, W.-H. Weng, H.~Fang, and P.~Szolovits.
\newblock What disease does this patient have? A large-scale open domain question answering dataset from medical exams.
\newblock \emph{Applied Sciences}, 11(14):6421, 2021.

\bibitem[Kadavath et~al.(2022)]{kadavath2022language}
S.~Kadavath, T.~Conerly, A.~Askell, et~al.
\newblock Language models (mostly) know what they know.
\newblock \emph{arXiv:2207.05221}, 2022.

\bibitem[Kahneman(2011)]{kahneman2011thinking}
D.~Kahneman.
\newblock \emph{Thinking, Fast and Slow}.
\newblock Farrar, Straus and Giroux, 2011.

\bibitem[Khot et~al.(2023)]{khot2023decomposed}
T.~Khot, H.~Trivedi, M.~Finlayson, et~al.
\newblock Decomposed prompting: A modular approach for solving complex tasks.
\newblock In \emph{ICLR}, 2023.

\bibitem[Nori et~al.(2023)]{nori2023can}
H.~Nori, N.~King, S.~M. McKinney, D.~Carignan, and E.~Horvitz.
\newblock Can generalist foundation models outcompete special-purpose tuning? Case study in medicine.
\newblock \emph{arXiv:2311.16452}, 2023.

\bibitem[Sackett et~al.(1996)]{sackett1996evidence}
D.~L. Sackett, W.~M. Rosenberg, J.~A.~M. Gray, R.~B. Haynes, and W.~S. Richardson.
\newblock Evidence based medicine: What it is and what it isn't.
\newblock \emph{BMJ}, 312(7023):71--72, 1996.

\bibitem[Saposnik et~al.(2016)]{saposnik2016cognitive}
G.~Saposnik, D.~Redelmeier, C.~C. Ruff, and P.~N. Tobler.
\newblock Cognitive biases associated with medical decisions: A systematic review.
\newblock \emph{BMC Medical Informatics and Decision Making}, 16(1):138, 2016.

\bibitem[Singhal et~al.(2023)]{singhal2023towards}
K.~Singhal, S.~Azizi, T.~Tu, et~al.
\newblock Towards expert-level medical question answering with large language models.
\newblock \emph{arXiv:2305.09617}, 2023.

\bibitem[Sutton et~al.(2020)]{sutton2020overview}
R.~T. Sutton, D.~Pincock, D.~C. Baumgart, D.~C. Sadowski, R.~N. Fedorak, and K.~I. Kroeker.
\newblock An overview of clinical decision support systems: Benefits, risks, and strategies for success.
\newblock \emph{NPJ Digital Medicine}, 3(1):17, 2020.

\bibitem[Thirunavukarasu et~al.(2023)]{thirunavukarasu2023large}
A.~J. Thirunavukarasu, D.~S.~J. Ting, K.~Elangovan, L.~Gutierrez, T.~F. Tan, and D.~S.~W. Ting.
\newblock Large language models in medicine.
\newblock \emph{Nature Medicine}, 29(8):1930--1940, 2023.

\bibitem[Wei et~al.(2022)]{wei2022chain}
J.~Wei, X.~Wang, D.~Schuurmans, et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock In \emph{NeurIPS}, 2022.

\end{thebibliography}

\end{document}
