# M6: è‡¨åºŠ LLM ä¿¡å¿ƒæ ¡æº–
# Calibration & Selective Prediction for Clinical LLMs: How Much Can We Trust AI Confidence?

> **å±¤ç´š**ï¼šLayer 4 â€” è¡Œç‚ºåˆ†æ
> **è²¡ç¶“å°æ‡‰**ï¼šD1 (Calibration & Selective Prediction)
> **ç‹€æ…‹**ï¼šğŸŸ¢ Ready â€” ç´”çµ±è¨ˆåˆ†æï¼Œä½¿ç”¨ç¾æœ‰ benchmark
> **Phase**ï¼šPhase 1ï¼ˆç«‹å³å¯åšï¼Œé–€æª»æœ€ä½ï¼‰

---

## ç ”ç©¶å•é¡Œ (Research Problem)

è‡¨åºŠ AI éƒ¨ç½²çš„æ ¸å¿ƒå•é¡Œä¸åƒ…æ˜¯ã€Œæ¨¡å‹ç­”å°å¤šå°‘ã€ï¼Œæ›´æ˜¯ã€Œæ¨¡å‹çŸ¥ä¸çŸ¥é“è‡ªå·±ä»€éº¼æ™‚å€™æœƒç­”éŒ¯ã€ã€‚ä¸€å€‹ 80% æº–ç¢ºç‡çš„æ¨¡å‹ï¼Œå¦‚æœèƒ½å®Œç¾è­˜åˆ¥è‡ªå·±æœƒç­”éŒ¯çš„ 20%ï¼ˆä¸¦æ‹’çµ•å›ç­”ï¼‰ï¼Œå°±æ¯”ä¸€å€‹ 90% æº–ç¢ºç‡ä½†ç„¡æ³•è¾¨åˆ¥è‡ªèº«éŒ¯èª¤çš„æ¨¡å‹æ›´é©åˆè‡¨åºŠä½¿ç”¨ã€‚

**æ ¡æº–ï¼ˆCalibrationï¼‰** è¡¡é‡çš„æ˜¯ï¼šæ¨¡å‹è¡¨é” 70% ä¿¡å¿ƒæ™‚ï¼Œæ˜¯å¦çœŸçš„æœ‰ 70% çš„æ¦‚ç‡æ˜¯æ­£ç¢ºçš„ï¼Ÿ

**é¸æ“‡æ€§é æ¸¬ï¼ˆSelective Predictionï¼‰** å›ç­”çš„æ˜¯ï¼šå¦‚æœæ¨¡å‹åªå›ç­”å®ƒæœ‰ä¿¡å¿ƒçš„å•é¡Œï¼Œèƒ½é”åˆ°å¤šé«˜çš„æº–ç¢ºç‡ï¼Ÿè¦é”åˆ° 95% æº–ç¢ºç‡ï¼ˆè‡¨åºŠå¯æ¥å—é–€æª»ï¼‰ï¼Œæ¨¡å‹éœ€è¦æ‹’çµ•å¤šå°‘æ¯”ä¾‹çš„å•é¡Œï¼Ÿ

**é€™å…©å€‹å•é¡Œå°è‡¨åºŠéƒ¨ç½²è‡³é—œé‡è¦ï¼š**
1. éåº¦æ ¡æº–ï¼ˆunder-confidentï¼‰â†’ éå¤šå•é¡Œè½‰äº¤äººå·¥ï¼Œç³»çµ±æ•ˆç‡ä½
2. æ ¡æº–ä¸è¶³ï¼ˆover-confidentï¼‰â†’ é«˜ä¿¡å¿ƒçš„éŒ¯èª¤ç­”æ¡ˆ â†’ ç—…æ‚£å®‰å…¨é¢¨éšª
3. å®‰å…¨é—œéµé ˜åŸŸï¼ˆè—¥ç†å­¸ã€æ€¥è¨ºï¼‰çš„æ ¡æº–æ˜¯å¦æ¯”ä¸€èˆ¬é ˜åŸŸæ›´å·®ï¼Ÿ

**é†«å­¸ç‰¹æ®Šæ€§ï¼š** ä¸æ˜¯æ‰€æœ‰éŒ¯èª¤éƒ½ä¸€æ¨£åš´é‡ã€‚è—¥ç†å­¸éŒ¯èª¤å¯èƒ½è‡´å‘½ï¼Œè§£å‰–å­¸çŸ¥è­˜ç¼ºå£é€šå¸¸ä¸å½±éŸ¿è™•ç½®ã€‚å› æ­¤éœ€è¦ **Safety-Weighted ECE**ï¼šè—¥ç†å­¸å’Œæ€¥è¨ºçš„æ ¡æº–èª¤å·®æ‡‰æœ‰æ›´é«˜çš„æ¬Šé‡ã€‚

---

## æ ¸å¿ƒæ–¹æ³• (Core Approach)

### 1. å››ç¨®ä¿¡å¿ƒä¼°è¨ˆæ–¹æ³• (Four Confidence Estimation Methods)

#### Method 1: Verbalized Confidenceï¼ˆèªè¨€åŒ–ä¿¡å¿ƒï¼‰

**Prompt è¨­è¨ˆï¼š**
```
Answer the following medical question. After your answer, state your confidence
level as a percentage (0-100%).

Question: [question]

Format:
Answer: [your answer]
Confidence: [X]%
```

**å„ªé»ï¼š** ç°¡å–®ã€é€šç”¨ã€ä¸éœ€ logit access
**ç¼ºé»ï¼š** æ¨¡å‹å¯èƒ½ä¸èª å¯¦ã€å— prompt è¨­è¨ˆå½±éŸ¿

#### Method 2: Self-Consistencyï¼ˆè‡ªæˆ‘ä¸€è‡´æ€§ï¼‰

**æ–¹æ³•ï¼š**
```
For each question:
  1. Run model k=10 times with temperature=0.7
  2. Collect 10 answers: {a_1, a_2, ..., a_10}
  3. Confidence = frequency of most common answer / k
     e.g., if 7/10 runs give same answer â†’ confidence = 70%
```

**å„ªé»ï¼š** ä¸ä¾è³´æ¨¡å‹è‡ªå ±ã€ç†è«–åŸºç¤å¼·ï¼ˆWang et al., 2023ï¼‰
**ç¼ºé»ï¼š** è¨ˆç®—æˆæœ¬é«˜ï¼ˆ10Ã— per questionï¼‰ã€å— temperature å½±éŸ¿

#### Method 3: Multi-Model Ensembleï¼ˆå¤šæ¨¡å‹é›†æˆï¼‰

**æ–¹æ³•ï¼š**
```
For each question:
  1. Run n models (e.g., 4 models) with temperature=0
  2. Collect n answers
  3. Confidence = agreement rate among models
     e.g., if 3/4 models agree â†’ confidence = 75%
```

**é¸ç”¨æ¨¡å‹çµ„åˆï¼š**
- Ensemble Aï¼ˆå¤§å‹ï¼‰ï¼šGPT-4o + Claude 3.5 + Qwen-32B + DeepSeek-R1-14B
- Ensemble Bï¼ˆå°å‹ï¼‰ï¼šLlama-8B + BioMistral-7B + Phi-3.5 + Med42

#### Method 4: Logit-based Confidenceï¼ˆåŸºæ–¼ Logit çš„ä¿¡å¿ƒï¼‰

**æ–¹æ³•ï¼ˆåƒ…é™ local models with logit accessï¼‰ï¼š**
```
For each question:
  1. Extract logit/probability for the chosen answer token
  2. Confidence = softmax probability of selected answer
  3. For MCQ: confidence = P(selected_option)
  4. For open-ended: confidence = geometric mean of token probabilities
```

**é©ç”¨æ¨¡å‹ï¼š** Ollama local modelsï¼ˆLlama, Qwen, DeepSeek, Phi, BioMistralï¼‰
**ä¸é©ç”¨ï¼š** Cloud modelsï¼ˆGPT-4o, Claude â€” ç„¡ logit accessï¼‰

### 2. æ ¡æº–æŒ‡æ¨™ (Calibration Metrics)

#### Expected Calibration Error (ECE)

$$\text{ECE} = \sum_{b=1}^{B} \frac{n_b}{N} |\text{acc}(b) - \text{conf}(b)|$$

- å°‡é æ¸¬ä¿¡å¿ƒåˆ†æˆ B=10 å€‹ç­‰å¯¬ bin
- $n_b$ = ç¬¬ b å€‹ bin ä¸­çš„æ¨£æœ¬æ•¸
- $\text{acc}(b)$ = ç¬¬ b å€‹ bin çš„å¯¦éš›æº–ç¢ºç‡
- $\text{conf}(b)$ = ç¬¬ b å€‹ bin çš„å¹³å‡ä¿¡å¿ƒ
- ç¯„åœ 0-1ï¼Œ0 = å®Œç¾æ ¡æº–

#### Maximum Calibration Error (MCE)

$$\text{MCE} = \max_{b \in \{1,...,B\}} |\text{acc}(b) - \text{conf}(b)|$$

- æœ€å·®çš„å–®ä¸€ binï¼Œè¡¡é‡æœ€åš´é‡çš„æ ¡æº–åå·®

#### Brier Score

$$\text{Brier} = \frac{1}{N} \sum_{i=1}^{N} (\text{conf}_i - \text{correct}_i)^2$$

- $\text{correct}_i \in \{0, 1\}$
- ç¯„åœ 0-1ï¼Œ0 = å®Œç¾
- åŒæ™‚æ‡²ç½°ä¸æº–ç¢ºå’Œæ ¡æº–ä¸è‰¯

#### Safety-Weighted ECEï¼ˆæœ¬ç ”ç©¶å‰µæ–°æŒ‡æ¨™ï¼‰

$$\text{SW-ECE} = \sum_{b=1}^{B} \frac{\sum_{i \in b} w_i}{\sum_{i} w_i} |\text{acc}(b) - \text{conf}(b)|$$

å…¶ä¸­å®‰å…¨æ¬Šé‡ $w_i$ æŒ‰é†«å­¸å­é ˜åŸŸè¨­å®šï¼š

| å­é ˜åŸŸ | å®‰å…¨æ¬Šé‡ $w$ | ç†ç”± |
|--------|-------------|------|
| è—¥ç†å­¸ (Pharmacology) | 3.0 | ç”¨è—¥éŒ¯èª¤å¯èƒ½è‡´å‘½ |
| æ€¥è¨ºé†«å­¸ (Emergency Med) | 3.0 | å»¶èª¤è™•ç½®å¯èƒ½è‡´å‘½ |
| å…§ç§‘ (Internal Medicine) | 2.0 | æ…¢æ€§ç—…ç®¡ç†å½±éŸ¿å¤§ |
| å¤–ç§‘ (Surgery) | 2.0 | æ‰‹è¡“æ±ºç­–å½±éŸ¿å¤§ |
| å°å…’ç§‘ (Pediatrics) | 2.5 | å…’ç«¥åŠ‘é‡è¨ˆç®—é—œéµ |
| å©¦ç”¢ç§‘ (OB/GYN) | 2.5 | å­•æœŸç”¨è—¥å®‰å…¨ |
| åŸºç¤é†«å­¸ (Basic Sciences) | 1.0 | é€šå¸¸ä¸ç›´æ¥å½±éŸ¿è™•ç½® |
| å…¶ä»– | 1.5 | é è¨­ä¸­ç­‰æ¬Šé‡ |

### 3. é¸æ“‡æ€§é æ¸¬æ¡†æ¶ (Selective Prediction Framework)

**æ ¸å¿ƒå•é¡Œï¼š** åœ¨ X% çš„æº–ç¢ºç‡é–€æª»ä¸‹ï¼Œæ¨¡å‹èƒ½å›ç­”å¤šå°‘æ¯”ä¾‹çš„å•é¡Œï¼Ÿ

**Coverage-Accuracy Tradeoffï¼š**

$$\text{Coverage}(\tau) = \frac{|\{i : \text{conf}_i \geq \tau\}|}{N}$$

$$\text{Accuracy}(\tau) = \frac{|\{i : \text{conf}_i \geq \tau \wedge \text{correct}_i = 1\}|}{|\{i : \text{conf}_i \geq \tau\}|}$$

- $\tau$ = ä¿¡å¿ƒé–€æª»
- ç¹ªè£½ Coverage vs Accuracy æ›²ç·š
- æ‰¾åˆ° Accuracy = 95% æ™‚çš„ Coverage â†’ è‡¨åºŠéƒ¨ç½²çš„å¯¦ç”¨æŒ‡æ¨™

**AUROC for Confidenceï¼š**

$$\text{AUROC} = P(\text{conf}(\text{correct}) > \text{conf}(\text{incorrect}))$$

- è¡¡é‡ä¿¡å¿ƒæ˜¯å¦èƒ½æœ‰æ•ˆå€åˆ†æ­£ç¢ºå’ŒéŒ¯èª¤å›ç­”
- é«˜ AUROC â†’ ä¿¡å¿ƒå¯ä½œç‚ºå¯é çš„å“è³ªéæ¿¾å™¨

---

## å¯¦é©—è¨­è¨ˆ (Experimental Design)

### å¯¦é©— 1ï¼šæ ¡æº–è©•ä¼°ï¼ˆä¸»è¦å¯¦é©—ï¼‰

**è¨­è¨ˆï¼š** 4 methods Ã— 8 models Ã— 3 datasets

**æµç¨‹ï¼š**
```
For each model M in {8 models}:
  For each dataset D in {MedQA, MedMCQA, MMLU-Med}:
    For each question Q in D:
      1. Method 1 (Verbalized): Run with confidence prompt â†’ conf_verb
      2. Method 2 (Self-Consistency): Run 10Ã— at temp=0.7 â†’ conf_sc
      3. Method 3 (Ensemble): Run 4-model ensemble â†’ conf_ens
      4. Method 4 (Logit): Extract logprobs (if available) â†’ conf_logit
    Compute per method:
      - ECE, MCE, Brier Score
      - SW-ECE
      - Reliability Diagram (10-bin)
      - AUROC
```

**æ¨è«–æ¬¡æ•¸ï¼š**
- Method 1: 6,256 Ã— 8 = 50,048
- Method 2: 6,256 Ã— 10 Ã— 8 = 500,480ï¼ˆæœ€å¤§æˆæœ¬é …ï¼‰
- Method 3: 6,256 Ã— 4 (or 8) = 25,024 (or 50,048)
- Method 4: included in Method 1 runs for local models
- **ç¸½è¨ˆï¼š~575,000+ æ¬¡æ¨è«–**

**æˆæœ¬æ§åˆ¶ç­–ç•¥ï¼š**
- Method 2 å¯å…ˆå° MedQA (1,273) åšå®Œæ•´ 10 runsï¼ŒMedMCQA ç”¨ k=5
- Cloud models åªåš Method 1 + Method 3
- Local models åšå…¨éƒ¨ 4 methods

### å¯¦é©— 2ï¼šå­é ˜åŸŸæ ¡æº–åˆ†æ

**æŒ‰é†«å­¸å­é ˜åŸŸæ‹†è§£æ ¡æº–æŒ‡æ¨™ï¼š**

```
For each model Ã— method:
  For each medical subtopic T:
    Compute ECE(T), SW-ECE(T), AUROC(T)
  Generate: Topic Ã— Model ECE ç†±åŠ›åœ–
  Identify: æ ¡æº–æœ€å·®çš„å­é ˜åŸŸ
```

**å‡è¨­æª¢é©—ï¼š**
- H1ï¼šè—¥ç†å­¸çš„ ECE > åŸºç¤é†«å­¸çš„ ECEï¼ˆè—¥ç†å­¸æ›´å®¹æ˜“éåº¦è‡ªä¿¡ï¼‰
- H2ï¼šå›°é›£å­é ˜åŸŸçš„éåº¦è‡ªä¿¡æ›´åš´é‡
- H3ï¼šé†«å­¸ç‰¹åŒ–æ¨¡å‹åœ¨é†«å­¸å­é ˜åŸŸçš„æ ¡æº–æ¯”é€šç”¨æ¨¡å‹å¥½

### å¯¦é©— 3ï¼šCoverage-Accuracy Tradeoff

**æ ¸å¿ƒè‡¨åºŠéƒ¨ç½²æŒ‡æ¨™ï¼š**

```
For each model Ã— method:
  1. Sort questions by confidence (descending)
  2. For Ï„ in [0.0, 0.05, 0.10, ..., 1.0]:
     Compute Coverage(Ï„) and Accuracy(Ï„)
  3. Plot Coverage-Accuracy curve
  4. Find Ï„* where Accuracy(Ï„*) = 0.95
  5. Report Coverage(Ï„*) = "at 95% accuracy, model can answer X% of questions"
```

**è‡¨åºŠè§£è®€ç¤ºä¾‹ï¼š**
- ã€ŒGPT-4o åœ¨ 95% æº–ç¢ºç‡é–€æª»ä¸‹å¯è‡ªå‹•å›ç­” MedQA ä¸­ 62% çš„å•é¡Œã€
- ã€ŒBioMistral-7B åœ¨ç›¸åŒé–€æª»ä¸‹åªèƒ½è‡ªå‹•å›ç­” 28% çš„å•é¡Œã€
- â†’ ç›´æ¥æŒ‡å°éƒ¨ç½²æ±ºç­–

### å¯¦é©— 4ï¼šä¿¡å¿ƒæ–¹æ³•æ¯”è¼ƒ

**æ¯”è¼ƒ 4 ç¨®ä¿¡å¿ƒä¼°è¨ˆæ–¹æ³•çš„å“è³ªï¼š**

| è©•æ¯”ç¶­åº¦ | è¡¡é‡æ–¹å¼ |
|---------|---------|
| æ ¡æº–å“è³ª | ECE, MCE, Brier Score æ’å |
| å€åˆ†èƒ½åŠ› | AUROC æ’å |
| é¸æ“‡æ€§é æ¸¬æ•ˆèƒ½ | Coverage@95% Accuracy |
| è¨ˆç®—æˆæœ¬ | API calls / inference time |
| å¯ç”¨æ€§ | éœ€è¦ logit access? |

**Recommendation Matrixï¼š** æ ¹æ“šä½¿ç”¨å ´æ™¯æ¨è–¦æœ€ä½³æ–¹æ³•
- è‡¨åºŠéƒ¨ç½²ï¼ˆreal-timeï¼‰â†’ å„ªå…ˆè€ƒæ…® Method 1 æˆ– 4
- é›¢ç·šæ‰¹æ¬¡è©•ä¼° â†’ Method 2 æä¾›æœ€å¯é çš„ä¿¡å¿ƒ
- å¤šæ¨¡å‹å¯ç”¨ â†’ Method 3

### å¯¦é©— 5ï¼šã€Œéåº¦è‡ªä¿¡ä¸”éŒ¯èª¤ã€æ¡ˆä¾‹åˆ†æ

**æå–æœ€å±éšªçš„æ¡ˆä¾‹ï¼šHigh Confidence + Wrong Answer**

```
Dangerous cases = {q : conf(q) > 0.8 AND correct(q) = 0}

For each dangerous case:
  1. Record: question, model answer, correct answer, confidence, topic
  2. Categorize: why was the model overconfident?
     a. Plausible but wrong (close distractor)
     b. Knowledge gap masked by fluency
     c. Systematic misconception
     d. Outdated knowledge with high certainty
  3. Assess clinical severity (4-level from M8)
```

**é€™äº›æ¡ˆä¾‹ç›´æ¥è¼¸å…¥ M8ï¼ˆPatient Safety Risk Matrixï¼‰**

---

## éœ€è¦çš„ç©æœ¨ (Required Building Blocks)

### è³‡æ–™é›†
| è³‡æº | è¦æ¨¡ | ç‹€æ…‹ | å‚™è¨» |
|------|------|------|------|
| MedQA USMLE Test | 1,273 | âœ… å·²å°±ç·’ | ä¸»è¦è³‡æ–™é›† |
| MedMCQA Test | 4,183 | âœ… å·²å°±ç·’ | å¤§è¦æ¨¡æ¸¬è©¦ |
| MMLU-Med (6 tasks) | ~800 | âœ… å·²å°±ç·’ | è£œå……è³‡æ–™é›† |
| PubMedQA | 1,000 | âœ… å…¬é–‹å¯å¾— | yes/no/maybe æ ¼å¼ï¼Œæ ¡æº–å¤©ç„¶é©åˆ |

### æ¨¡å‹ï¼ˆå« logit éœ€æ±‚ï¼‰
| æ¨¡å‹ | Logit Access | Methods å¯ç”¨ | ç‹€æ…‹ |
|------|-------------|-------------|------|
| GPT-4o | âŒ | 1, 2, 3 | âœ… |
| GPT-4o-mini | âŒ | 1, 2, 3 | âœ… |
| Claude 3.5 | âŒ | 1, 2, 3 | âœ… |
| Llama 3.1 8B | âœ… (Ollama logprobs) | 1, 2, 3, 4 | âœ… |
| Qwen 2.5 32B | âœ… | 1, 2, 3, 4 | âœ… |
| DeepSeek-R1 14B | âœ… | 1, 2, 3, 4 | âœ… |
| BioMistral-7B | âœ… (llama.cpp) | 1, 2, 3, 4 | âœ… |
| Med42-v2 | âœ… | 1, 2, 3, 4 | âŒ éœ€ä¸‹è¼‰ |

### å·¥å…·
| å·¥å…· | ç”¨é€” | ç‹€æ…‹ |
|------|------|------|
| netcal (Python) | æ ¡æº–åˆ†æåº« | âŒ éœ€å®‰è£ |
| scikit-learn | AUROC, reliability diagram | âœ… |
| matplotlib + seaborn | è¦–è¦ºåŒ– | âœ… |

---

## é æœŸç”¢å‡º (Expected Outputs)

### ä»£ç¢¼ç”¢å‡º
```
results/M6_calibration_metrics.csv               # ECE, MCE, Brier per modelÃ—methodÃ—dataset
results/M6_swece_by_topic.csv                    # SW-ECE per modelÃ—topic
results/M6_coverage_accuracy.csv                 # Coverage-Accuracy curve data
results/M6_auroc.csv                             # AUROC per modelÃ—method
results/M6_overconfident_wrong_cases.json        # High-conf wrong answer cases
results/M6_method_comparison.csv                 # 4-method comparison table
```

### è¦–è¦ºåŒ–
```
figures/M6_reliability_diagrams/                  # 8 models Ã— 4 methods = 32 diagrams
figures/M6_ece_heatmap_model_x_topic.png         # Model Ã— Topic ECE ç†±åŠ›åœ–
figures/M6_coverage_accuracy_curves.png          # Coverage-Accuracy overlay
figures/M6_swece_vs_ece_comparison.png           # SW-ECE vs standard ECE
figures/M6_method_comparison_radar.png           # 4-method æ¯”è¼ƒé›·é”åœ–
figures/M6_overconfident_distribution.png        # éåº¦è‡ªä¿¡æ¡ˆä¾‹åˆ†å¸ƒ
```

### å­¸è¡“è¡¨æ ¼
- Table 1: Calibration Metrics (ECE, MCE, Brier) by Model, Method, and Dataset
- Table 2: Safety-Weighted ECE by Medical Subdomain
- Table 3: Coverage at 95% Accuracy Threshold by Model and Method
- Table 4: AUROC for Confidence-Correctness Discrimination
- Table 5: Confidence Estimation Method Comparison (Quality, Cost, Applicability)
- Table 6: High-Confidence Wrong Answer Analysis (Top 20 Cases)

---

## é æœŸç™¼ç¾ (Expected Findings)

1. **æ‰€æœ‰æ¨¡å‹éƒ½éåº¦è‡ªä¿¡**ï¼šECE é æœŸ > 0.10ï¼ˆç†æƒ³å€¼ 0ï¼‰ï¼Œé¡¯ç¤ºç³»çµ±æ€§çš„ over-confidence
2. **è—¥ç†å­¸æ ¡æº–æœ€å·®**ï¼šè—¥ç†å­¸å­é ˜åŸŸçš„ ECE é æœŸæœ€é«˜ï¼ŒSW-ECE æ›´åŠ çªå‡ºå·®ç•°
3. **Self-Consistency æ ¡æº–æœ€ä½³**ï¼šMethod 2 çš„ ECE é æœŸæœ€ä½ï¼Œä½†è¨ˆç®—æˆæœ¬æœ€é«˜
4. **Coverage å·®ç•°å¤§**ï¼šGPT-4o åœ¨ 95% æº–ç¢ºç‡ä¸‹å¯èƒ½è¦†è“‹ 50-65%ï¼ŒBioMistral å¯èƒ½åªæœ‰ 20-30%
5. **Verbalized â‰  True Confidence**ï¼šæ¨¡å‹è‡ªå ±ä¿¡å¿ƒèˆ‡åŸºæ–¼ logit çš„ä¿¡å¿ƒå¯èƒ½å·®ç•°é¡¯è‘—
6. **éåº¦è‡ªä¿¡éŒ¯èª¤é›†ä¸­åœ¨ç‰¹å®šé ˜åŸŸ**ï¼šé«˜ä¿¡å¿ƒ+éŒ¯èª¤çš„æ¡ˆä¾‹é æœŸé›†ä¸­åœ¨ã€Œæ¨¡å‹ä¼¼ä¹çŸ¥é“ä½†å¯¦éš›éæ™‚ã€çš„çŸ¥è­˜é ˜åŸŸ

---

## é†«å­¸ç‰¹æœ‰åƒ¹å€¼

1. **éƒ¨ç½²é–€æª»è¨­å®š**ï¼šCoverage@95% ç›´æ¥å›ç­”ã€Œéƒ¨ç½²é€™å€‹æ¨¡å‹ï¼Œå¤šå°‘æ¯”ä¾‹çš„è‡¨åºŠå•é¡Œå¯ä»¥è‡ªå‹•å›ç­”ï¼Ÿã€
2. **Safety-Weighted ECE å‰µæ–°**ï¼šé¦–æ¬¡åœ¨ LLM æ ¡æº–ç ”ç©¶ä¸­å¼•å…¥è‡¨åºŠåš´é‡åº¦åŠ æ¬Š
3. **é¢¨éšªåˆ†æµä¾æ“š**ï¼šæ ¡æº–è‰¯å¥½çš„æ¨¡å‹å¯ç”¨æ–¼ä½é¢¨éšªå•é¡Œè‡ªå‹•å›ç­”ï¼Œé«˜é¢¨éšªå•é¡Œè½‰äº¤äººå·¥
4. **ç›´æ¥é€£çµ M8**ï¼šéåº¦è‡ªä¿¡ä¸”éŒ¯èª¤çš„æ¡ˆä¾‹ç›´æ¥è¼¸å…¥ M8 çš„é¢¨éšªçŸ©é™£
5. **RAG ç³»çµ±ä¿¡å¿ƒæ•´åˆ**ï¼šæ ¡æº–çµæœå¯æŒ‡å°ç¾æœ‰ Medical-RAG ç³»çµ±æ˜¯å¦/å¦‚ä½•å±•ç¤ºä¿¡å¿ƒåˆ†æ•¸

---

## å¯åˆä½µçš„é»å­ (Related Ideas)

| ç›¸é—œæ§‹æƒ³ | é—œä¿‚ | èªªæ˜ |
|---------|------|------|
| M1 (Open-Ended) | â†” å…±ç”¨è³‡æ–™é›† | M1 å’Œ M6 ä½¿ç”¨ç›¸åŒåº•å±¤ benchmark |
| M3 (Error Atlas) | â† æä¾›ä¿¡å¿ƒ | M6 çš„ä¿¡å¿ƒæ•¸æ“šè£œå…… M3 çš„ã€ŒE2 è™›å‡ç¢ºä¿¡ã€åˆ†æ |
| M8 (Safety Matrix) | â†’ ç›´æ¥ä¸‹æ¸¸ | M6 çš„éåº¦è‡ªä¿¡æ¡ˆä¾‹ç›´æ¥è¼¸å…¥ M8 |
| M9 (RxLLama) | â†’ ä¸‹æ¸¸ | M6 çš„æ ¡æº–æ–¹æ³•æ‡‰ç”¨æ–¼ M9 çš„è©•ä¼°é‡è¨­è¨ˆ |

---

## ä¾†æºç­†è¨˜ (References & Sources)

### å­¸è¡“æ–‡ç»
- Guo, C., et al. (2017). On calibration of modern neural networks. *ICML 2017*.
- Kadavath, S., et al. (2022). Language models (mostly) know what they know. *arXiv:2207.05221*.
- Wang, X., et al. (2023). Self-consistency improves chain of thought reasoning in language models. *ICLR 2023*.
- Naeini, M.P., et al. (2015). Obtaining well calibrated probabilities using Bayesian binning into quantiles. *AAAI 2015*.
- Nori, H., et al. (2023). Can Generalist Foundation Models Outcompete Special-Purpose Tuning? *arXiv:2311.16452*.
- Tian, K., et al. (2023). Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models with optimized prompting. *arXiv:2305.14975*.
- Singhal, K., et al. (2023). Large Language Models Encode Clinical Knowledge. *Nature*.

### å…§éƒ¨æ–‡ä»¶
- `åƒè€ƒ/selected/D1-calibration-selective-prediction.md` â€” è²¡ç¶“ç‰ˆæ ¡æº–åˆ†ææ–¹æ³•è«–

### å·¥å…·
- netcal: https://github.com/EFS-OpenSource/calibration-framework
- Ollama logprobs API: https://github.com/ollama/ollama/blob/main/docs/api.md
